{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:54.696095Z",
     "start_time": "2024-01-04T17:24:49.505369300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 加载需要的库\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.datasets import StuperDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import  load_preproc_data_stuper\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import FairEduNet\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据集和设置选项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:54.907520200Z",
     "start_time": "2024-01-04T17:24:54.691094300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取数据集，进行训练集和测试集的划分\n",
    "dataset_orig = load_preproc_data_stuper()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.9], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:54.919433300Z",
     "start_time": "2024-01-04T17:24:54.908520Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 41)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'schoolsup_encoded', 'famsup_encoded', 'paid_encoded', 'activities_encoded', 'nursery_encoded', 'higher_encoded', 'internet_encoded', 'romantic_encoded', 'school_MS', 'address_U', 'famsize_LE3', 'Pstatus_T', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother', 'guardian_other', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher']\n"
     ]
    }
   ],
   "source": [
    "# 打印出数据集的一些特征\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原始训练数据的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:54.925854Z",
     "start_time": "2024-01-04T17:24:54.919433300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.151784\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.052296\n"
     ]
    }
   ],
   "source": [
    "# 原始数据集的指标\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:55.013385Z",
     "start_time": "2024-01-04T17:24:54.927854300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.151784\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.052296\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "# 缩放数据集 - 验证缩放是否不会影响组标签统计数据\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习计划分类器，无需去偏见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:24:55.013385Z",
     "start_time": "2024-01-04T17:24:54.944990300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:08.200947700Z",
     "start_time": "2024-01-04T17:24:54.950385600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 3; batch classifier mean loss: 0.661435\n",
      "epoch 1; iter: 3; batch classifier mean loss: 0.533345\n",
      "epoch 2; iter: 3; batch classifier mean loss: 0.453167\n",
      "epoch 3; iter: 3; batch classifier mean loss: 0.407376\n",
      "epoch 4; iter: 3; batch classifier mean loss: 0.359507\n",
      "epoch 5; iter: 3; batch classifier mean loss: 0.309493\n",
      "epoch 6; iter: 3; batch classifier mean loss: 0.284718\n",
      "epoch 7; iter: 3; batch classifier mean loss: 0.292950\n",
      "epoch 8; iter: 3; batch classifier mean loss: 0.259302\n",
      "epoch 9; iter: 3; batch classifier mean loss: 0.206016\n",
      "epoch 10; iter: 3; batch classifier mean loss: 0.162740\n",
      "epoch 11; iter: 3; batch classifier mean loss: 0.144100\n",
      "epoch 12; iter: 3; batch classifier mean loss: 0.128121\n",
      "epoch 13; iter: 3; batch classifier mean loss: 0.100032\n",
      "epoch 14; iter: 3; batch classifier mean loss: 0.157014\n",
      "epoch 15; iter: 3; batch classifier mean loss: 0.177179\n",
      "epoch 16; iter: 3; batch classifier mean loss: 0.073843\n",
      "epoch 17; iter: 3; batch classifier mean loss: 0.087650\n",
      "epoch 18; iter: 3; batch classifier mean loss: 0.064340\n",
      "epoch 19; iter: 3; batch classifier mean loss: 0.058340\n",
      "epoch 20; iter: 3; batch classifier mean loss: 0.051298\n",
      "epoch 21; iter: 3; batch classifier mean loss: 0.047399\n",
      "epoch 22; iter: 3; batch classifier mean loss: 0.039856\n",
      "epoch 23; iter: 3; batch classifier mean loss: 0.032240\n",
      "epoch 24; iter: 3; batch classifier mean loss: 0.023588\n",
      "epoch 25; iter: 3; batch classifier mean loss: 0.027299\n",
      "epoch 26; iter: 3; batch classifier mean loss: 0.017261\n",
      "epoch 27; iter: 3; batch classifier mean loss: 0.018131\n",
      "epoch 28; iter: 3; batch classifier mean loss: 0.016127\n",
      "epoch 29; iter: 3; batch classifier mean loss: 0.014740\n",
      "epoch 30; iter: 3; batch classifier mean loss: 0.010748\n",
      "epoch 31; iter: 3; batch classifier mean loss: 0.008156\n",
      "epoch 32; iter: 3; batch classifier mean loss: 0.008486\n",
      "epoch 33; iter: 3; batch classifier mean loss: 0.006819\n",
      "epoch 34; iter: 3; batch classifier mean loss: 0.005437\n",
      "epoch 35; iter: 3; batch classifier mean loss: 0.003219\n",
      "epoch 36; iter: 3; batch classifier mean loss: 0.003393\n",
      "epoch 37; iter: 3; batch classifier mean loss: 0.002930\n",
      "epoch 38; iter: 3; batch classifier mean loss: 0.002917\n",
      "epoch 39; iter: 3; batch classifier mean loss: 0.002711\n",
      "epoch 40; iter: 3; batch classifier mean loss: 0.002370\n",
      "epoch 41; iter: 3; batch classifier mean loss: 0.002110\n",
      "epoch 42; iter: 3; batch classifier mean loss: 0.002453\n",
      "epoch 43; iter: 3; batch classifier mean loss: 0.002582\n",
      "epoch 44; iter: 3; batch classifier mean loss: 0.001489\n",
      "epoch 45; iter: 3; batch classifier mean loss: 0.006211\n",
      "epoch 46; iter: 3; batch classifier mean loss: 0.005192\n",
      "epoch 47; iter: 3; batch classifier mean loss: 0.003045\n",
      "epoch 48; iter: 3; batch classifier mean loss: 0.006122\n",
      "epoch 49; iter: 3; batch classifier mean loss: 0.003743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x88012210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:08.451862600Z",
     "start_time": "2024-01-04T17:25:08.202968200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将朴素模型应用于测试数据\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:08.467822600Z",
     "start_time": "2024-01-04T17:25:08.451862600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.151784\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.177296\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.876923\n",
      "Test set: Balanced classification accuracy = 0.875237\n",
      "Test set: Disparate impact = 0.638021\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Average odds difference = -0.140357\n",
      "Test set: Theil_index = 0.097267\n"
     ]
    }
   ],
   "source": [
    "# 朴素模型数据集的度量指标（未去偏见）\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用基于Adversarial Debiasing的处理中算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:08.477834700Z",
     "start_time": "2024-01-04T17:25:08.466807400Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:08.478856700Z",
     "start_time": "2024-01-04T17:25:08.471986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "# 在去偏见设置为True时学习参数\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess,\n",
    "                          num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:25.197322300Z",
     "start_time": "2024-01-04T17:25:08.477834700Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 3; batch classifier mean loss: 0.638059; batch adversarial mean loss: 0.691876\n",
      "epoch 1; iter: 3; batch classifier mean loss: 0.503656; batch adversarial mean loss: 0.685790\n",
      "epoch 2; iter: 3; batch classifier mean loss: 0.456047; batch adversarial mean loss: 0.687217\n",
      "epoch 3; iter: 3; batch classifier mean loss: 0.416042; batch adversarial mean loss: 0.697506\n",
      "epoch 4; iter: 3; batch classifier mean loss: 0.353159; batch adversarial mean loss: 0.686744\n",
      "epoch 5; iter: 3; batch classifier mean loss: 0.310251; batch adversarial mean loss: 0.684307\n",
      "epoch 6; iter: 3; batch classifier mean loss: 0.413262; batch adversarial mean loss: 0.681708\n",
      "epoch 7; iter: 3; batch classifier mean loss: 0.394231; batch adversarial mean loss: 0.683374\n",
      "epoch 8; iter: 3; batch classifier mean loss: 0.541277; batch adversarial mean loss: 0.642848\n",
      "epoch 9; iter: 3; batch classifier mean loss: 0.459646; batch adversarial mean loss: 0.697707\n",
      "epoch 10; iter: 3; batch classifier mean loss: 0.357230; batch adversarial mean loss: 0.659521\n",
      "epoch 11; iter: 3; batch classifier mean loss: 0.288987; batch adversarial mean loss: 0.669889\n",
      "epoch 12; iter: 3; batch classifier mean loss: 0.297118; batch adversarial mean loss: 0.674597\n",
      "epoch 13; iter: 3; batch classifier mean loss: 0.308602; batch adversarial mean loss: 0.683523\n",
      "epoch 14; iter: 3; batch classifier mean loss: 0.268836; batch adversarial mean loss: 0.675938\n",
      "epoch 15; iter: 3; batch classifier mean loss: 0.245807; batch adversarial mean loss: 0.672569\n",
      "epoch 16; iter: 3; batch classifier mean loss: 0.211739; batch adversarial mean loss: 0.675201\n",
      "epoch 17; iter: 3; batch classifier mean loss: 0.201427; batch adversarial mean loss: 0.678951\n",
      "epoch 18; iter: 3; batch classifier mean loss: 0.196953; batch adversarial mean loss: 0.668491\n",
      "epoch 19; iter: 3; batch classifier mean loss: 0.191654; batch adversarial mean loss: 0.666944\n",
      "epoch 20; iter: 3; batch classifier mean loss: 0.233673; batch adversarial mean loss: 0.671306\n",
      "epoch 21; iter: 3; batch classifier mean loss: 0.226608; batch adversarial mean loss: 0.682735\n",
      "epoch 22; iter: 3; batch classifier mean loss: 0.176091; batch adversarial mean loss: 0.673085\n",
      "epoch 23; iter: 3; batch classifier mean loss: 0.177775; batch adversarial mean loss: 0.675816\n",
      "epoch 24; iter: 3; batch classifier mean loss: 0.167886; batch adversarial mean loss: 0.673621\n",
      "epoch 25; iter: 3; batch classifier mean loss: 0.122128; batch adversarial mean loss: 0.676258\n",
      "epoch 26; iter: 3; batch classifier mean loss: 0.131165; batch adversarial mean loss: 0.674210\n",
      "epoch 27; iter: 3; batch classifier mean loss: 0.112603; batch adversarial mean loss: 0.676267\n",
      "epoch 28; iter: 3; batch classifier mean loss: 0.109892; batch adversarial mean loss: 0.672996\n",
      "epoch 29; iter: 3; batch classifier mean loss: 0.094939; batch adversarial mean loss: 0.674014\n",
      "epoch 30; iter: 3; batch classifier mean loss: 0.075630; batch adversarial mean loss: 0.670190\n",
      "epoch 31; iter: 3; batch classifier mean loss: 0.076985; batch adversarial mean loss: 0.673929\n",
      "epoch 32; iter: 3; batch classifier mean loss: 0.076064; batch adversarial mean loss: 0.679785\n",
      "epoch 33; iter: 3; batch classifier mean loss: 0.095293; batch adversarial mean loss: 0.682848\n",
      "epoch 34; iter: 3; batch classifier mean loss: 0.122043; batch adversarial mean loss: 0.680571\n",
      "epoch 35; iter: 3; batch classifier mean loss: 0.178945; batch adversarial mean loss: 0.685835\n",
      "epoch 36; iter: 3; batch classifier mean loss: 0.467712; batch adversarial mean loss: 0.692324\n",
      "epoch 37; iter: 3; batch classifier mean loss: 0.546768; batch adversarial mean loss: 0.685977\n",
      "epoch 38; iter: 3; batch classifier mean loss: 0.301447; batch adversarial mean loss: 0.688220\n",
      "epoch 39; iter: 3; batch classifier mean loss: 0.263416; batch adversarial mean loss: 0.680692\n",
      "epoch 40; iter: 3; batch classifier mean loss: 0.320252; batch adversarial mean loss: 0.693361\n",
      "epoch 41; iter: 3; batch classifier mean loss: 0.169371; batch adversarial mean loss: 0.674920\n",
      "epoch 42; iter: 3; batch classifier mean loss: 0.139813; batch adversarial mean loss: 0.679689\n",
      "epoch 43; iter: 3; batch classifier mean loss: 0.097238; batch adversarial mean loss: 0.671301\n",
      "epoch 44; iter: 3; batch classifier mean loss: 0.094017; batch adversarial mean loss: 0.681485\n",
      "epoch 45; iter: 3; batch classifier mean loss: 0.098778; batch adversarial mean loss: 0.680692\n",
      "epoch 46; iter: 3; batch classifier mean loss: 0.251151; batch adversarial mean loss: 0.680089\n",
      "epoch 47; iter: 3; batch classifier mean loss: 0.715975; batch adversarial mean loss: 0.696582\n",
      "epoch 48; iter: 3; batch classifier mean loss: 1.594638; batch adversarial mean loss: 0.679609\n",
      "epoch 49; iter: 3; batch classifier mean loss: 1.185185; batch adversarial mean loss: 0.683052\n",
      "epoch 50; iter: 3; batch classifier mean loss: 0.401762; batch adversarial mean loss: 0.673594\n",
      "epoch 51; iter: 3; batch classifier mean loss: 0.445366; batch adversarial mean loss: 0.681983\n",
      "epoch 52; iter: 3; batch classifier mean loss: 0.320677; batch adversarial mean loss: 0.673986\n",
      "epoch 53; iter: 3; batch classifier mean loss: 0.305117; batch adversarial mean loss: 0.675443\n",
      "epoch 54; iter: 3; batch classifier mean loss: 0.394090; batch adversarial mean loss: 0.690081\n",
      "epoch 55; iter: 3; batch classifier mean loss: 0.253209; batch adversarial mean loss: 0.676737\n",
      "epoch 56; iter: 3; batch classifier mean loss: 0.288503; batch adversarial mean loss: 0.669522\n",
      "epoch 57; iter: 3; batch classifier mean loss: 0.311053; batch adversarial mean loss: 0.687873\n",
      "epoch 58; iter: 3; batch classifier mean loss: 0.389580; batch adversarial mean loss: 0.695561\n",
      "epoch 59; iter: 3; batch classifier mean loss: 0.266433; batch adversarial mean loss: 0.682573\n",
      "epoch 60; iter: 3; batch classifier mean loss: 0.191699; batch adversarial mean loss: 0.678329\n",
      "epoch 61; iter: 3; batch classifier mean loss: 0.156595; batch adversarial mean loss: 0.678456\n",
      "epoch 62; iter: 3; batch classifier mean loss: 0.135712; batch adversarial mean loss: 0.676818\n",
      "epoch 63; iter: 3; batch classifier mean loss: 0.138286; batch adversarial mean loss: 0.678766\n",
      "epoch 64; iter: 3; batch classifier mean loss: 0.117146; batch adversarial mean loss: 0.674293\n",
      "epoch 65; iter: 3; batch classifier mean loss: 0.102855; batch adversarial mean loss: 0.679787\n",
      "epoch 66; iter: 3; batch classifier mean loss: 0.091915; batch adversarial mean loss: 0.681799\n",
      "epoch 67; iter: 3; batch classifier mean loss: 0.087561; batch adversarial mean loss: 0.680203\n",
      "epoch 68; iter: 3; batch classifier mean loss: 0.072257; batch adversarial mean loss: 0.673753\n",
      "epoch 69; iter: 3; batch classifier mean loss: 0.065300; batch adversarial mean loss: 0.684076\n",
      "epoch 70; iter: 3; batch classifier mean loss: 0.060959; batch adversarial mean loss: 0.677540\n",
      "epoch 71; iter: 3; batch classifier mean loss: 0.057353; batch adversarial mean loss: 0.673505\n",
      "epoch 72; iter: 3; batch classifier mean loss: 0.100147; batch adversarial mean loss: 0.679161\n",
      "epoch 73; iter: 3; batch classifier mean loss: 0.231581; batch adversarial mean loss: 0.686904\n",
      "epoch 74; iter: 3; batch classifier mean loss: 0.237796; batch adversarial mean loss: 0.688858\n",
      "epoch 75; iter: 3; batch classifier mean loss: 0.137781; batch adversarial mean loss: 0.683523\n",
      "epoch 76; iter: 3; batch classifier mean loss: 0.112727; batch adversarial mean loss: 0.685806\n",
      "epoch 77; iter: 3; batch classifier mean loss: 0.121086; batch adversarial mean loss: 0.680997\n",
      "epoch 78; iter: 3; batch classifier mean loss: 0.105241; batch adversarial mean loss: 0.681071\n",
      "epoch 79; iter: 3; batch classifier mean loss: 0.102486; batch adversarial mean loss: 0.680326\n",
      "epoch 80; iter: 3; batch classifier mean loss: 0.106319; batch adversarial mean loss: 0.680767\n",
      "epoch 81; iter: 3; batch classifier mean loss: 0.091530; batch adversarial mean loss: 0.686466\n",
      "epoch 82; iter: 3; batch classifier mean loss: 0.091484; batch adversarial mean loss: 0.682172\n",
      "epoch 83; iter: 3; batch classifier mean loss: 0.096440; batch adversarial mean loss: 0.683069\n",
      "epoch 84; iter: 3; batch classifier mean loss: 0.111429; batch adversarial mean loss: 0.683549\n",
      "epoch 85; iter: 3; batch classifier mean loss: 0.123633; batch adversarial mean loss: 0.684486\n",
      "epoch 86; iter: 3; batch classifier mean loss: 0.130130; batch adversarial mean loss: 0.687916\n",
      "epoch 87; iter: 3; batch classifier mean loss: 0.128471; batch adversarial mean loss: 0.687590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 3; batch classifier mean loss: 0.142778; batch adversarial mean loss: 0.684917\n",
      "epoch 89; iter: 3; batch classifier mean loss: 0.145354; batch adversarial mean loss: 0.683135\n",
      "epoch 90; iter: 3; batch classifier mean loss: 0.135888; batch adversarial mean loss: 0.685983\n",
      "epoch 91; iter: 3; batch classifier mean loss: 0.127344; batch adversarial mean loss: 0.687124\n",
      "epoch 92; iter: 3; batch classifier mean loss: 0.120164; batch adversarial mean loss: 0.686232\n",
      "epoch 93; iter: 3; batch classifier mean loss: 0.106697; batch adversarial mean loss: 0.685535\n",
      "epoch 94; iter: 3; batch classifier mean loss: 0.143915; batch adversarial mean loss: 0.681896\n",
      "epoch 95; iter: 3; batch classifier mean loss: 0.117295; batch adversarial mean loss: 0.682944\n",
      "epoch 96; iter: 3; batch classifier mean loss: 0.086398; batch adversarial mean loss: 0.680587\n",
      "epoch 97; iter: 3; batch classifier mean loss: 0.091212; batch adversarial mean loss: 0.683343\n",
      "epoch 98; iter: 3; batch classifier mean loss: 0.103494; batch adversarial mean loss: 0.680168\n",
      "epoch 99; iter: 3; batch classifier mean loss: 0.111488; batch adversarial mean loss: 0.678916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x864efad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:25.552217700Z",
     "start_time": "2024-01-04T17:25:25.190321800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将朴素模型应用于测试数据\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:25.582524800Z",
     "start_time": "2024-01-04T17:25:25.557214700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.151784\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.177296\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.035018\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.014031\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.876923\n",
      "Test set: Statistical parity difference = -0.177296\n",
      "Test set: Equalized Odds difference = -0.160714\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Disparate impact = 0.638021\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.846154\n",
      "Test set: Statistical parity difference = -0.014031\n",
      "Test set: Equalized Odds difference = 0.047619\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Disparate impact = 0.957031\n"
     ]
    }
   ],
   "source": [
    "# 朴素模型数据集的度量指标（不去偏见）\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# # 去偏见的模型数据集的度量指标\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "\n",
    "# print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "# print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "# print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "# print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "# print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_nodebiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Equalized Odds difference = %f\" % classified_metric_nodebiasing_test.equalized_odds_difference())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Equalized Odds difference = %f\" % classified_metric_debiasing_test.equalized_odds_difference())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:25.615944600Z",
     "start_time": "2024-01-04T17:25:25.581521100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
